from typing import List, Dict, Any, Annotated, Optional
from typing_extensions import TypedDict
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages
from .llm_interface import LLMInterface
from .tool_interface import ToolInterface, ToolResult
import re
from dataclasses import asdict

# LangGraphã®Stateå®šç¾©
class State(TypedDict):
    """ãƒãƒ£ãƒƒãƒˆAgentã®çŠ¶æ…‹ç®¡ç†"""
    messages: Annotated[List[BaseMessage], add_messages]
    original_question: str  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•
    plan: str  # ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ©ãƒ³
    target_city: Optional[str]  # å¯¾è±¡éƒ½å¸‚å
    city_confirmed: bool  # éƒ½å¸‚ãŒç¢ºå®šã•ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹
    gathered_info: str  # å–å¾—ã—ãŸæƒ…å ±
    needs_city_info: bool  # éƒ½å¸‚æƒ…å ±ãŒå¿…è¦ã‹ã©ã†ã‹
    tools_executed: bool  # ãƒ„ãƒ¼ãƒ«ãŒå®Ÿè¡Œæ¸ˆã¿ã‹ã©ã†ã‹
    function_calls: List[Dict[str, Any]]  # å®Ÿè¡Œã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã®æƒ…å ±
    retry_count: int  # ãƒªãƒˆãƒ©ã‚¤å›æ•°
    tool_results: List[ToolResult]  # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã®ãƒªã‚¹ãƒˆ

class ChatAgent:
    """Travel Planning Assistant using LangGraph for structured conversation flow"""
    
    def __init__(self, llm: LLMInterface, tools: List[ToolInterface]):
        """
        Initialize ChatAgent for travel planning assistance
        
        Args:
            llm: LangChain ChatModel instance
            tools: List of available tools for gathering travel information
        """
        self.llm = llm
        self.tool_interfaces = tools
        
        # LangChainãƒ„ãƒ¼ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—
        self.langchain_tools = [tool.get_langchain_tool() for tool in tools]
        self.llm_with_tools = self.llm.bind_tools(self.langchain_tools)
        
        # LangGraphã‚’æ§‹ç¯‰
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """LangGraphã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ï¼ˆai-agent.mdè¨­è¨ˆé€šã‚Šï¼‰"""
        # StateGraphã‚’ä½œæˆ
        graph_builder = StateGraph(State)
        
        # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        graph_builder.add_node("plan", self._plan_generation_node)
        graph_builder.add_node("ask_city", self._ask_city_node)
        graph_builder.add_node("gather_info", self._gather_info_node)
        graph_builder.add_node("tools", ToolNode(self.langchain_tools))
        graph_builder.add_node("check_tool_results", self._check_tool_results_node)
        graph_builder.add_node("mark_tools_executed", self._mark_tools_executed_node)
        graph_builder.add_node("compose", self._compose_answer_node)
        
        # ã‚¨ãƒƒã‚¸ã‚’è¨­å®š
        graph_builder.add_edge(START, "plan")
        
        # ãƒ—ãƒ©ãƒ³ç”Ÿæˆå¾Œã®æ¡ä»¶åˆ†å²
        graph_builder.add_conditional_edges(
            "plan",
            self._determine_city,
            {
                "ask_city": "ask_city",
                "gather_info": "gather_info",
                "compose": "compose",
            }
        )
        
        # éƒ½å¸‚åè³ªå•å¾Œã¯çµ‚äº†ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ¬¡ã®å…¥åŠ›ã‚’å¾…ã¤ï¼‰
        graph_builder.add_edge("ask_city", END)
        
        # æƒ…å ±å–å¾—å¾Œã®æ¡ä»¶åˆ†å²
        graph_builder.add_conditional_edges(
            "gather_info",
            self._should_use_tools,
            {
                "tools": "tools",
                "compose": "compose",
            }
        )
        
        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¾Œã¯ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†
        graph_builder.add_edge("tools", "check_tool_results")
        
        # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯å¾Œã®æ¡ä»¶åˆ†å²
        graph_builder.add_conditional_edges(
            "check_tool_results",
            self._should_retry_tools,
            {
                "retry": "gather_info",  # ãƒªãƒˆãƒ©ã‚¤ãŒå¿…è¦ãªå ´åˆ
                "success": "mark_tools_executed",  # æˆåŠŸã—ãŸå ´åˆ
            }
        )
        
        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œæ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’è¨­å®šã—ã¦ã‹ã‚‰æƒ…å ±å–å¾—ã«æˆ»ã‚‹
        graph_builder.add_edge("mark_tools_executed", "gather_info")
        
        # æœ€çµ‚å›ç­”ç”Ÿæˆå¾Œã¯çµ‚äº†
        graph_builder.add_edge("compose", END)
        
        return graph_builder.compile()
    
    def _plan_generation_node(self, state: State) -> Dict[str, Any]:
        """ãƒ—ãƒ©ãƒ³ç”ŸæˆNode - LLMã«è³ªå•åˆ†æã‚’å§”ã­ã‚‹"""
        messages = state["messages"]
        if not messages:
            return state
        
        # æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
        user_message = None
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                user_message = msg.content
                break
        
        if not user_message:
            return state
        
        # LLMã«åˆ†æã‚’å…¨ã¦å§”ã­ã‚‹
        system_prompt = """You are a travel planning assistant that helps users discuss and plan their trips. Analyze the user's message and respond in the following JSON format:

{
  "target_city": "city name or unknown",
  "needs_city_info": true/false,
  "city_confirmed": true/false,
  "analysis": "brief analysis of the request",
  "planned_actions": "description of what you will do next",
  "tools_to_use": ["list of tools you plan to use"]
}

For questions about travel, weather, attractions, food, or general city information for trip planning, set needs_city_info to true.
If a city name is clearly mentioned, set city_confirmed to true.
In planned_actions, explain what steps you will take to help with their travel planning.
In tools_to_use, list the specific tools you intend to use (e.g., "weather_tool", "city_facts_tool", "time_tool")."""

        planning_message = HumanMessage(content=user_message)
        plan_response = self.llm.invoke([SystemMessage(content=system_prompt), planning_message])
        plan_content = plan_response.content if hasattr(plan_response, 'content') else str(plan_response)
        
        # JSONã‹ã‚‰å€¤ã‚’æŠ½å‡ºï¼ˆLLMã®å‡ºåŠ›ã‚’ãã®ã¾ã¾ä¿¡é ¼ï¼‰
        target_city = self._extract_json_value(plan_content, "target_city")
        needs_city_info = "true" in str(self._extract_json_value(plan_content, "needs_city_info")).lower()
        city_confirmed = "true" in str(self._extract_json_value(plan_content, "city_confirmed")).lower()
        
        return {
            "original_question": user_message,
            "plan": plan_content,
            "target_city": target_city if target_city != "ä¸æ˜" else None,
            "city_confirmed": city_confirmed,
            "needs_city_info": needs_city_info,
            "gathered_info": state.get("gathered_info", ""),
            "function_calls": state.get("function_calls", [])
        }
    
    def _determine_city(self, state: State) -> str:
        """å¯¾è±¡éƒ½å¸‚ãŒç¢ºå®šã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        needs_city_info = state.get("needs_city_info", False)
        city_confirmed = state.get("city_confirmed", False)
        
        if needs_city_info and not city_confirmed:
            return "ask_city"
        elif needs_city_info and city_confirmed:
            return "gather_info"
        else:
            return "compose"
    
    def _ask_city_node(self, state: State) -> Dict[str, List[BaseMessage]]:
        """éƒ½å¸‚åã‚’è³ªå•ã™ã‚‹Node"""
        question_message = AIMessage(
            content="Which city would you like to explore for your travel planning? Please tell me the city name."
        )
        return {"messages": [question_message]}
    
    def _gather_info_node(self, state: State) -> Dict[str, Any]:
        """éƒ½å¸‚æƒ…å ±å–å¾—Node - ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦æƒ…å ±ã‚’åé›†"""
        target_city = state.get("target_city")
        if not target_city:
            return state
        
        retry_count = state.get("retry_count", 0)
        tool_results = state.get("tool_results", [])
        
        # æœ€æ–°ã®å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ«ã‹ã‚‰æœ€åˆã«å¤±æ•—ã—ãŸãƒ„ãƒ¼ãƒ«ã‚’å–å¾—
        first_failed_result = None
        function_calls = state.get("function_calls", [])
        recent_results_count = len(function_calls) if function_calls else 1
        recent_results = tool_results[-recent_results_count:] if recent_results_count <= len(tool_results) else tool_results
        
        # å®Ÿè¡Œé †ã§æœ€åˆã«å¤±æ•—ã—ãŸãƒ„ãƒ¼ãƒ«ã‚’ç‰¹å®š
        for result in recent_results:
            # ToolResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹è¾æ›¸ã‹ã‚’åˆ¤å®š
            success = result.success if hasattr(result, 'success') else result.get('success', True)
            if not success:
                first_failed_result = result
                break
        
        # ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è€ƒæ…®ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        if first_failed_result and retry_count > 0:
            error_message = first_failed_result.error_message if hasattr(first_failed_result, 'error_message') else str(first_failed_result.get('error_message', ''))
            failed_tool_name = first_failed_result.tool_name if hasattr(first_failed_result, 'tool_name') else first_failed_result.get('tool_name', 'unknown')
            
            system_prompt = f"""Please gather travel information for "{target_city}".
A previous tool execution failed with error: {error_message}
Failed tool: {failed_tool_name}

Please adjust the city name format according to the error message:
- For non-English city names, try using English format with country code (e.g., "Tokyo,JP")
- Check the spelling and add country code if needed
- Use proper formatting expected by the API

Important: Please retry using the same "{failed_tool_name}" tool that failed. Do not switch to different tools, but instead fix the parameters and retry the same tool."""
            user_content = f"Please retry gathering information for {target_city} (retry #{retry_count}, using {failed_tool_name} tool)"
        else:
            system_prompt = f"""Please gather travel information for "{target_city}". Use appropriate tools to collect useful information for trip planning including weather, attractions, local time, and other relevant details."""
            user_content = f"Please gather travel information for {target_city}"
        
        user_request = HumanMessage(content=user_content)
        
        # ãƒ„ãƒ¼ãƒ«ä»˜ãLLMã«å•ã„åˆã‚ã›
        response = self.llm_with_tools.invoke([SystemMessage(content=system_prompt), user_request])
        
        # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—æƒ…å ±ã‚’è¨˜éŒ²
        function_calls = list(state.get("function_calls", []))
        for tool_call in response.tool_calls:
            if isinstance(tool_call, dict):
                # è¾æ›¸å½¢å¼ã®å ´åˆ
                tool_name = tool_call.get("name", "unknown")
                tool_args = tool_call.get("args", {})
            else:
                # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®å ´åˆ
                tool_name = getattr(tool_call, "name", None) or getattr(tool_call, "function", {}).get("name", "unknown")
                tool_args = getattr(tool_call, "args", None) or getattr(tool_call, "function", {}).get("arguments", {})
            
            function_call_info = {
                "tool": tool_name,
                "parameters": tool_args
            }
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if not any(
                fc.get("tool") == function_call_info["tool"] and 
                fc.get("parameters") == function_call_info["parameters"] 
                for fc in function_calls
            ):
                function_calls.append(function_call_info)
        
        # ãƒªãƒˆãƒ©ã‚¤æ™‚ã¯ã‚«ã‚¦ãƒ³ãƒˆã‚’æ›´æ–°
        updated_retry_count = retry_count + 1 if first_failed_result else retry_count
        
        return {
            "messages": [response],
            "gathered_info": state.get("gathered_info", ""),
            "function_calls": function_calls,
            "retry_count": updated_retry_count
        }
    
    def _check_tool_results_node(self, state: State) -> Dict[str, Any]:
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ToolResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ"""
        messages = state["messages"]
        tool_results = list(state.get("tool_results", []))
        function_calls = state.get("function_calls", [])
        
        # æœ€æ–°ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ«ã®ToolMessageã‚’å…¨ã¦å–å¾—
        tool_messages = []
        for msg in reversed(messages):
            if isinstance(msg, ToolMessage) and hasattr(msg, 'content') and msg.content:
                tool_messages.append(msg)
            elif len(tool_messages) > 0:
                # ToolMessageä»¥å¤–ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå‡ºç¾ã—ãŸã‚‰ã€ãã“ã§æœ€æ–°ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ«ã¯çµ‚äº†
                break
        
        # ãƒ„ãƒ¼ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å®Ÿè¡Œé †ã«ä¸¦ã³æ›¿ãˆï¼ˆreversedã§å–å¾—ã—ãŸãŸã‚ï¼‰
        tool_messages.reverse()
        
        # å„ãƒ„ãƒ¼ãƒ«çµæœã‚’å‡¦ç†
        for i, msg in enumerate(tool_messages):
            content_str = str(msg.content)
            
            # å®Ÿè¡Œã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«åã‚’ç‰¹å®š
            executed_tool_name = "unknown"
            if hasattr(msg, 'name') and msg.name:
                executed_tool_name = msg.name
            elif i < len(function_calls):
                executed_tool_name = function_calls[i].get("tool", "unknown")
            
            # ã‚¨ãƒ©ãƒ¼ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
            error_indicators = ["error", "ã‚¨ãƒ©ãƒ¼", "not found", "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", "failed", "å¤±æ•—"]
            is_error = any(indicator.lower() in content_str.lower() for indicator in error_indicators)
            
            if is_error:
                # ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã‚’åˆ¤å®š
                error_type = "retryable"
                if "not found" in content_str.lower() or "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“" in content_str.lower():
                    error_type = "retryable"  # éƒ½å¸‚åã®å•é¡Œã¯ä¿®æ­£å¯èƒ½
                elif "invalid" in content_str.lower() or "unauthorized" in content_str.lower():
                    error_type = "non-retryable"
                
                tool_result = ToolResult(
                    success=False,
                    error_message=content_str,
                    error_type=error_type,
                    tool_name=executed_tool_name
                )
            else:
                # æˆåŠŸã¨ã—ã¦æ‰±ã†
                tool_result = ToolResult(
                    success=True,
                    data=content_str,
                    tool_name=executed_tool_name
                )
            
            tool_results.append(tool_result)
        
        return {"tool_results": tool_results}
    
    def _should_retry_tools(self, state: State) -> str:
        """ãƒªãƒˆãƒ©ã‚¤ãŒå¿…è¦ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        max_retries = 2
        retry_count = state.get("retry_count", 0)
        tool_results = state.get("tool_results", [])
        
        # ãƒ„ãƒ¼ãƒ«çµæœãŒãªã„å ´åˆã¯æˆåŠŸã¨ã—ã¦æ‰±ã†
        if not tool_results:
            return "success"
        
        # æœ€æ–°ã®å®Ÿè¡Œã‚µã‚¤ã‚¯ãƒ«ã®ãƒ„ãƒ¼ãƒ«çµæœã‚’å–å¾—ï¼ˆæœ€å¾Œã‹ã‚‰å®Ÿè¡Œã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«æ•°åˆ†ï¼‰
        function_calls = state.get("function_calls", [])
        recent_results_count = len(function_calls) if function_calls else 1
        recent_results = tool_results[-recent_results_count:] if recent_results_count <= len(tool_results) else tool_results
        
        # ä¸€ã¤ã§ã‚‚ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        failed_results = []
        for result in recent_results:
            # ToolResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹è¾æ›¸ã‹ã‚’åˆ¤å®š
            success = result.success if hasattr(result, 'success') else result.get('success', True)
            if not success:
                failed_results.append(result)
        
        # å…¨ã¦æˆåŠŸã—ã¦ã„ã‚Œã°æˆåŠŸ
        if not failed_results:
            return "success"
        
        # ãƒªãƒˆãƒ©ã‚¤ä¸Šé™ã«é”ã—ã¦ã„ã‚Œã°æˆåŠŸã¨ã—ã¦æ‰±ã†
        if retry_count >= max_retries:
            return "success"
        
        # å¤±æ•—ã—ãŸãƒ„ãƒ¼ãƒ«ã®ã†ã¡ã€ãƒªãƒˆãƒ©ã‚¤å¯èƒ½ãªã‚‚ã®ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        retryable_errors = []
        for failed_result in failed_results:
            error_type = failed_result.error_type if hasattr(failed_result, 'error_type') else failed_result.get('error_type', 'non-retryable')
            if error_type == "retryable":
                retryable_errors.append(failed_result)
        
        # ãƒªãƒˆãƒ©ã‚¤å¯èƒ½ãªã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã¯ãƒªãƒˆãƒ©ã‚¤
        if retryable_errors:
            return "retry"
        else:
            return "success"  # ãƒªãƒˆãƒ©ã‚¤ä¸å¯èƒ½ãªã‚¨ãƒ©ãƒ¼ã®ã¿ã®å ´åˆã¯æˆåŠŸã¨ã—ã¦æ‰±ã†
    
    def _mark_tools_executed_node(self, state: State) -> Dict[str, bool]:
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œæ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’è¨­å®šã™ã‚‹Node"""
        return {"tools_executed": True}
    
    def _should_use_tools(self, state: State) -> str:
        """ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        # æ—¢ã«ãƒ„ãƒ¼ãƒ«ãŒå®Ÿè¡Œæ¸ˆã¿ã®å ´åˆã¯å›ç­”ç”Ÿæˆã«ç§»è¡Œ
        if state.get("tools_executed", False):
            return "compose"
        
        messages = state["messages"]
        if not messages:
            return "compose"
        
        last_message = messages[-1]
        # ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ãŒã‚ã‚‹å ´åˆã¯ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "tools"
        return "compose"
    
    def _compose_answer_node(self, state: State) -> Dict[str, List[BaseMessage]]:
        """å›ç­”ç”ŸæˆNode - LLMã«å›ç­”ç”Ÿæˆã‚’å§”ã­ã‚‹"""
        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡ŒçµæœãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        tool_results = state.get("tool_results", [])
        successful_results = []
        
        for result in tool_results:
            # ToolResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹è¾æ›¸ã‹ã‚’åˆ¤å®š
            if isinstance(result, dict):
                if result.get("success", False):
                    successful_results.append(result)
            else:
                # ToolResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                if getattr(result, "success", False):
                    successful_results.append(result)
        
        # æˆåŠŸã—ãŸãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‚’ã™ã¹ã¦ä½¿ç”¨ã—ã¦å›ç­”ç”Ÿæˆ
        if successful_results:
            # è¤‡æ•°ãƒ„ãƒ¼ãƒ«ã®çµæœã‚’ã¾ã¨ã‚ã‚‹
            combined_results = []
            for result in successful_results:
                if isinstance(result, dict):
                    tool_name = result.get("tool_name") or result.get("tool") or "unknown"
                    data = result.get("data", "")
                else:
                    tool_name = getattr(result, "tool_name", "unknown")
                    data = getattr(result, "data", "")
                
                if data:
                    combined_results.append(f"[{tool_name}]\n{data}")
            
            # ã¾ã¨ã‚ãŸçµæœã‚’é€£çµ
            data_block = "\n\n".join(combined_results)
            
            system_prompt = f"""You are a helpful and knowledgeable travel planning assistant. 
Generate a natural and useful response in English using the following tool execution results to help the user plan their trip.

Tool execution results:
{data_block}

Please organize this information clearly in English for travel planning purposes.
Display temperatures in Celsius and provide practical travel advice based on the gathered information.
Focus on helping the user understand what to expect and how to plan their trip effectively."""
            
        else:
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡ŒçµæœãŒãªã„å ´åˆã®é€šå¸¸ã®å›ç­”ç”Ÿæˆ
            system_prompt = """You are a helpful and knowledgeable travel planning assistant.
Understand the conversation context and generate a natural and useful response in English for the user's travel planning needs.
If you have information from tools, interpret it appropriately and present it clearly for trip planning purposes."""
        
        # åŸºæœ¬çš„ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        messages = [SystemMessage(content=system_prompt)]
        for msg in state["messages"]:
            if isinstance(msg, (HumanMessage, AIMessage)):
                if hasattr(msg, 'content') and msg.content:
                    messages.append(msg)
        
        # LLMã«å›ç­”ç”Ÿæˆã‚’å§”ã­ã‚‹
        response = self.llm.invoke(messages)
        return {"messages": [response]}
    
    def _extract_json_value(self, text: str, key: str):
        """JSONãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å€¤ã‚’æŠ½å‡ºï¼ˆæ–‡å­—åˆ—ã€ãƒªã‚¹ãƒˆã€ãã®ä»–ã®å‹ã«å¯¾å¿œï¼‰"""
        import json
        try:
            # JSONå…¨ä½“ã‚’ãƒ‘ãƒ¼ã‚¹
            json_match = re.search(r'\{.*\}', text, re.DOTALL)
            if json_match:
                json_data = json.loads(json_match.group())
                return json_data.get(key)
        except:
            # JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯æ­£è¦è¡¨ç¾ã§æŠ½å‡º
            # ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆ
            list_pattern = rf'"{key}"\s*:\s*\[(.*?)\]'
            list_match = re.search(list_pattern, text, re.DOTALL)
            if list_match:
                try:
                    # ãƒªã‚¹ãƒˆã®å†…å®¹ã‚’ãƒ‘ãƒ¼ã‚¹
                    list_content = list_match.group(1).strip()
                    if list_content:
                        # ç°¡å˜ãªãƒªã‚¹ãƒˆãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œ
                        items = [item.strip().strip('"\'') for item in list_content.split(',')]
                        return [item for item in items if item]
                    return []
                except:
                    return list_match.group(1).strip()
            
            # æ–‡å­—åˆ—å½¢å¼ã®å ´åˆ
            pattern = rf'"{key}"\s*:\s*"?([^",\n]+)"?'
            match = re.search(pattern, text)
            return match.group(1).strip() if match else None
        return None
    
    async def chat(self, message: str, conversation_history: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Main entry point for travel planning chat processing
        
        Args:
            message: User's message about travel planning
            conversation_history: Previous conversation history
            
        Returns:
            Dictionary containing AI response, thinking process, and executed tool information
            {
                "response": str,  # AI's travel planning response
                "thinking": str,  # Thought process (plan analysis)
                "function_calls": List[Dict[str, Any]]  # Information about executed tools
            }
        """
        try:
            # ä¼šè©±å±¥æ­´ã‚’LangChainã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›
            messages = []
            if conversation_history:
                for msg in conversation_history[-5:]:  # ToDo: é•·ã„å ´åˆã¯åœ§ç¸®ã™ã‚‹ãªã©ã®å‡¦ç†ã‚’è¿½åŠ 
                    if msg["role"] == "user":
                        messages.append(HumanMessage(content=msg["content"]))
                    elif msg["role"] == "assistant":
                        messages.append(AIMessage(content=msg["content"]))
            
            # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            messages.append(HumanMessage(content=message))
            
            # åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
            initial_state = {
                "messages": messages,
                "original_question": "",
                "plan": "",
                "target_city": None,
                "city_confirmed": False,
                "gathered_info": "",
                "needs_city_info": False,
                "tools_executed": False,
                "function_calls": [],
                "retry_count": 0,
                "tool_results": []
            }
            
            # ã‚°ãƒ©ãƒ•ã‚’å®Ÿè¡Œï¼ˆå†å¸°åˆ¶é™ã‚’è¨­å®šï¼‰
            config = {"recursion_limit": 25}
            result = await self.graph.ainvoke(initial_state, config=config)
            
            # çµæœã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€thinkingã€function_callsã‚’å–å¾—
            response = "I apologize, but I was unable to generate a response."
            thinking = result.get("plan", "Processing your message...")
            function_calls = result.get("function_calls", [])
            
            # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
            if result and "messages" in result and result["messages"]:
                last_message = result["messages"][-1]
                if hasattr(last_message, 'content'):
                    response = last_message.content
            
            return {
                "response": response,
                "thinking": thinking,
                "function_calls": function_calls
            }
            
        except Exception as e:
            return {
                "response": "I apologize, but an error occurred while processing your request.",
                "thinking": "An error occurred during processing.",
                "function_calls": []
            }

    async def chat_stream(self, message: str, conversation_history: List[Dict[str, Any]] = None):
        """
        Streaming chat processing for travel planning (SSE compatible)
        
        Args:
            message: User's travel planning message
            conversation_history: Previous conversation history
            
        Yields:
            Dictionary containing execution results for each node
            {
                "event_type": str,  # "node_start", "node_complete", "final_response"
                "node_name": str,   # Name of the executing node
                "status": str,      # Status ("processing", "completed", "error")
                "message": str,     # User-facing message about travel planning progress
                "data": Dict[str, Any]  # Node execution results
            }
        """
        try:
            # ä¼šè©±å±¥æ­´ã‚’LangChainã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›
            messages = []
            if conversation_history:
                for msg in conversation_history[-5:]:
                    if msg["role"] == "user":
                        messages.append(HumanMessage(content=msg["content"]))
                    elif msg["role"] == "assistant":
                        messages.append(AIMessage(content=msg["content"]))
            
            # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            messages.append(HumanMessage(content=message))
            
            # åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
            initial_state = {
                "messages": messages,
                "original_question": "",
                "plan": "",
                "target_city": None,
                "city_confirmed": False,
                "gathered_info": "",
                "needs_city_info": False,
                "tools_executed": False,
                "function_calls": [],
                "retry_count": 0,
                "tool_results": []
            }
            
            # å‡¦ç†é–‹å§‹ã‚’é€šçŸ¥
            yield {
                "event_type": "processing_start",
                "node_name": "system",
                "status": "processing",
                "message": "Analyzing your travel planning request...",
                "data": {}
            }
            
            # ã‚°ãƒ©ãƒ•ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè¡Œ
            config = {"recursion_limit": 25}
            final_result = None
            
            async for chunk in self.graph.astream(initial_state, config=config):
                if not chunk:
                    continue
                
                # ãƒãƒ¼ãƒ‰åã¨çµæœã‚’å–å¾—
                node_name = list(chunk.keys())[0] if chunk else "unknown"
                node_result = chunk.get(node_name, {})
                
                # ãƒãƒ¼ãƒ‰ã”ã¨ã®å‡¦ç†çŠ¶æ³ã‚’æ—¥æœ¬èªã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åŒ–
                user_message = self._get_node_message(node_name, node_result)
                
                # ãƒãƒ¼ãƒ‰å®Ÿè¡Œå®Œäº†ã‚’é€šçŸ¥
                yield {
                    "event_type": "node_complete", 
                    "node_name": node_name,
                    "status": "completed",
                    "message": user_message,
                    "data": {
                        "result": self._serialize_node_result(node_result),
                        "plan": node_result.get("plan", ""),
                        "target_city": node_result.get("target_city", ""),
                        "function_calls": node_result.get("function_calls", [])
                    }
                }
                
                # æœ€çµ‚çµæœã‚’ä¿å­˜
                final_result = node_result
            
            # æœ€çµ‚å¿œç­”ã‚’ç”Ÿæˆ
            if final_result and "messages" in final_result and final_result["messages"]:
                last_message = final_result["messages"][-1]
                response = last_message.content if hasattr(last_message, 'content') else "Unable to generate a response."
            else:
                response = "I apologize, but I was unable to generate a response."
            
            # æœ€çµ‚å¿œç­”ã‚’é€ä¿¡
            yield {
                "event_type": "final_response",
                "node_name": "system",
                "status": "completed",
                "message": "Generated travel planning response",
                "data": {
                    "response": response,
                    "thinking": final_result.get("plan", ""),
                    "function_calls": final_result.get("function_calls", [])
                }
            }
            
        except Exception as e:
            yield {
                "event_type": "error",
                "node_name": "system",
                "status": "error",
                "message": "I apologize, but an error occurred while processing your travel planning request.",
                "data": {"error": str(e)}
            }
    
    def _get_node_message(self, node_name: str, node_result: Dict[str, Any]) -> str:
        """ãƒãƒ¼ãƒ‰ã®å®Ÿè¡ŒçŠ¶æ³ã‚’è‹±èªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›"""
        node_messages = {
            "plan": "Analyzing your travel request and creating a plan...",
            "ask_city": "Confirming the destination city...",
            "gather_info": "Gathering travel information...",
            "tools": "Executing tools to collect travel data...",
            "check_tool_results": "Checking tool execution results...",
            "mark_tools_executed": "Tool execution completed",
            "compose": "Generating your travel planning response..."
        }
        
        base_message = node_messages.get(node_name, f"Executing {node_name}...")
        
        # ãƒãƒ¼ãƒ‰çµæœã«åŸºã¥ã„ã¦ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’è¿½åŠ 
        if node_name == "plan" and "target_city" in node_result:
            city = node_result.get("target_city")
            needs_city_info = node_result.get("needs_city_info", False)
            city_confirmed = node_result.get("city_confirmed", False)
            
            # Extract planned actions and tools from the plan content
            plan_content = node_result.get("plan", "")
            planned_actions = self._extract_json_value(plan_content, "planned_actions")
            tools_to_use = self._extract_json_value(plan_content, "tools_to_use")
            
            if city and city != "unknown":
                base_message = f"âœ… Analyzed your request. Target destination: {city}"
                if planned_actions:
                    base_message += f"\nğŸ“‹ Plan: {planned_actions}"
                if tools_to_use:
                    if isinstance(tools_to_use, list):
                        tools_str = ", ".join(tools_to_use)
                    else:
                        # Handle string representation of list
                        tools_str = str(tools_to_use).strip('[]').replace("'", "").replace('"', '')
                    base_message += f"\nğŸ”§ Tools to use: {tools_str}"
            else:
                base_message = "Analyzed your request. Need to confirm the destination city."
                if planned_actions:
                    base_message += f" Once confirmed, I will: {planned_actions}"
        
        elif node_name == "gather_info" and "function_calls" in node_result:
            calls = node_result.get("function_calls", [])
            retry_count = node_result.get("retry_count", 0)
            if calls:
                tool_names = [call.get("tool", "unknown") for call in calls]
                if retry_count > 0:
                    base_message = f"Retrying information gathering (attempt #{retry_count}) using: {', '.join(tool_names)}"
                else:
                    base_message = f"Gathering information using tools: {', '.join(tool_names)}"
        
        elif node_name == "check_tool_results":
            tool_results = node_result.get("tool_results", [])
            last_result = tool_results[-1] if tool_results else None
            if last_result:
                # ToolResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹è¾æ›¸ã‹ã‚’åˆ¤å®š
                success = last_result.success if hasattr(last_result, 'success') else last_result.get('success', True)
                tool_name = last_result.tool_name if hasattr(last_result, 'tool_name') else last_result.get('tool_name', 'unknown')
                
                if not success:
                    base_message = f"Detected error in tool execution ({tool_name}). Considering retry..."
                else:
                    base_message = f"Tool execution completed successfully ({tool_name})"
            else:
                base_message = "Tool execution completed successfully"
        
        elif node_name == "tools" and "messages" in node_result:
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã‚’æŠ½å‡º
            messages = node_result.get("messages", [])
            tool_results = []
            for msg in messages:
                if hasattr(msg, 'content') and hasattr(msg, 'type'):
                    # LangChainã®ToolMessageã®å ´åˆ
                    if hasattr(msg, 'type') and 'tool' in str(msg.type).lower():
                        tool_results.append(msg.content)
                elif isinstance(msg, dict) and msg.get("type") == "tool":
                    # ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã•ã‚ŒãŸToolMessageã®å ´åˆ
                    tool_results.append(msg.get("content", ""))
            
            if tool_results:
                # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœã®æ¦‚è¦ã‚’è¡¨ç¤ºï¼ˆé•·ã™ãã‚‹å ´åˆã¯çŸ­ç¸®ï¼‰
                result_summary = tool_results[0][:100] + ("..." if len(tool_results[0]) > 100 else "")
                base_message = f"Tool execution completed: {result_summary}"
            else:
                base_message = "Tools executed successfully"
        
        elif node_name == "compose" and "messages" in node_result:
            base_message = "Generated final travel planning response"
        
        return base_message
    
    def _serialize_node_result(self, node_result: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒãƒ¼ãƒ‰çµæœã‚’JSON serializableãªå½¢å¼ã«å¤‰æ›"""
        if not isinstance(node_result, dict):
            return {}
        
        serialized = {}
        for key, value in node_result.items():
            if key == "tool_results" and isinstance(value, list):
                # ToolResultãƒªã‚¹ãƒˆã‚’å¤‰æ›
                serialized[key] = []
                for tool_result in value:
                    if isinstance(tool_result, ToolResult):
                        # ToolResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
                        serialized[key].append(asdict(tool_result))
                    else:
                        # æ—¢ã«è¾æ›¸å½¢å¼ã®å ´åˆã¯ãã®ã¾ã¾
                        serialized[key].append(tool_result)
            elif key == "messages" and isinstance(value, list):
                # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’å¤‰æ›
                serialized[key] = []
                for msg in value:
                    if hasattr(msg, 'content') and hasattr(msg, 'type'):
                        # LangChainãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                        msg_type = msg.type if hasattr(msg, 'type') else str(type(msg).__name__)
                        msg_role = getattr(msg, 'role', 'unknown')
                        
                        # ToolMessageã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†
                        if 'tool' in str(msg_type).lower():
                            msg_role = 'tool'
                        elif msg_type == 'ai':
                            msg_role = 'assistant'
                        elif msg_type == 'human':
                            msg_role = 'user'
                        
                        serialized[key].append({
                            "content": msg.content,
                            "type": msg_type,
                            "role": msg_role
                        })
                    else:
                        # æ™®é€šã®è¾æ›¸ã®å ´åˆ
                        serialized[key].append(str(msg))
            elif hasattr(value, 'content'):
                # å˜ä¸€ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                msg_type = value.type if hasattr(value, 'type') else str(type(value).__name__)
                msg_role = getattr(value, 'role', 'unknown')
                
                # ToolMessageã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†
                if 'tool' in str(msg_type).lower():
                    msg_role = 'tool'
                elif msg_type == 'ai':
                    msg_role = 'assistant'
                elif msg_type == 'human':
                    msg_role = 'user'
                
                serialized[key] = {
                    "content": value.content,
                    "type": msg_type,
                    "role": msg_role
                }
            elif isinstance(value, (str, int, float, bool, list, dict, type(None))):
                # JSON serializableãªåŸºæœ¬å‹ã®å ´åˆ
                serialized[key] = value
            else:
                # ãã®ä»–ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯æ–‡å­—åˆ—ã«å¤‰æ›
                serialized[key] = str(value)
        
        return serialized